{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# upload file"
      ],
      "metadata": {
        "id": "hGpA4WDE5iR8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gx7gV7Ie0_bR",
        "outputId": "e1058782-c2e4-4e7c-88d2-a884854e29e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… fer2013.zip è§£å£“å®Œæˆ\n",
            "âœ… raf-db.zip è§£å£“å®Œæˆ\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# è§£å£“ fer2013.zip åˆ° /content/fer2013\n",
        "fer_zip_path = \"/content/fer2013.zip\"\n",
        "fer_extract_path = \"/content/fer2013\"\n",
        "\n",
        "if os.path.exists(fer_zip_path):\n",
        "    with zipfile.ZipFile(fer_zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(fer_extract_path)\n",
        "    print(\"âœ… fer2013.zip è§£å£“å®Œæˆ\")\n",
        "else:\n",
        "    print(\"âŒ fer2013.zip æ‰¾ä¸åˆ°\")\n",
        "\n",
        "# è§£å£“ raf-db.zip åˆ° /content/raf-db\n",
        "raf_zip_path = \"/content/raf-db.zip\"\n",
        "raf_extract_path = \"/content/raf-db\"\n",
        "\n",
        "if os.path.exists(raf_zip_path):\n",
        "    with zipfile.ZipFile(raf_zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(raf_extract_path)\n",
        "    print(\"âœ… raf-db.zip è§£å£“å®Œæˆ\")\n",
        "else:\n",
        "    print(\"âŒ raf-db.zip æ‰¾ä¸åˆ°\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## check the structure of dataset"
      ],
      "metadata": {
        "id": "27r9hYZm5ynS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/fer2013\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEoUH9pM16Ip",
        "outputId": "27e10836-2a31-4146-e54c-85f00d8ba5db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test  train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/raf-db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dE-_3gq1-Lb",
        "outputId": "1391550a-10e9-4b46-aef7-3f8a9cd281ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATASET  test_labels.csv  train_labels.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def show_fer2013_structure(root_dir, indent=\"\", max_files=10):\n",
        "    for folder in sorted(os.listdir(root_dir)):\n",
        "        folder_path = os.path.join(root_dir, folder)\n",
        "        if os.path.isdir(folder_path):\n",
        "            print(f\"{indent}ğŸ“ {folder}/\")\n",
        "            count = 0\n",
        "            for file in sorted(os.listdir(folder_path)):\n",
        "                if os.path.isfile(os.path.join(folder_path, file)):\n",
        "                    if count < max_files:\n",
        "                        print(f\"{indent}    ğŸ“„ {file}\")\n",
        "                        count += 1\n",
        "                    elif count == max_files:\n",
        "                        print(f\"{indent}    ... (more files hidden)\")\n",
        "                        break\n",
        "\n",
        "print(\"ğŸ—‚ï¸  fer2013 è³‡æ–™å¤¾çµæ§‹:\\n\")\n",
        "fer_path = \"/content/fer2013\"\n",
        "if os.path.exists(fer_path):\n",
        "    for split in [\"train\", \"val\"]:\n",
        "        split_path = os.path.join(fer_path, split)\n",
        "        print(f\"ğŸ“ {split}/\")\n",
        "        if os.path.exists(split_path):\n",
        "            show_fer2013_structure(split_path, indent=\"    \")\n",
        "        else:\n",
        "            print(\"    âŒ è©²å­è³‡æ–™å¤¾ä¸å­˜åœ¨\")\n",
        "else:\n",
        "    print(\"âŒ fer2013 è³‡æ–™å¤¾ä¸å­˜åœ¨\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2KxfLs02jQb",
        "outputId": "75dfab6d-622c-4219-e5fa-42093a0a3dcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ—‚ï¸  fer2013 è³‡æ–™å¤¾çµæ§‹:\n",
            "\n",
            "ğŸ“ train/\n",
            "    ğŸ“ angry/\n",
            "        ğŸ“„ Training_10118481.jpg\n",
            "        ğŸ“„ Training_10120469.jpg\n",
            "        ğŸ“„ Training_10131352.jpg\n",
            "        ğŸ“„ Training_10161559.jpg\n",
            "        ğŸ“„ Training_1021836.jpg\n",
            "        ğŸ“„ Training_10269675.jpg\n",
            "        ğŸ“„ Training_10278738.jpg\n",
            "        ğŸ“„ Training_10290703.jpg\n",
            "        ğŸ“„ Training_10295477.jpg\n",
            "        ğŸ“„ Training_10315441.jpg\n",
            "        ... (more files hidden)\n",
            "    ğŸ“ disgust/\n",
            "        ğŸ“„ Training_10371709.jpg\n",
            "        ğŸ“„ Training_10598340.jpg\n",
            "        ğŸ“„ Training_1070239.jpg\n",
            "        ğŸ“„ Training_11050021.jpg\n",
            "        ğŸ“„ Training_11550217.jpg\n",
            "        ğŸ“„ Training_11652168.jpg\n",
            "        ğŸ“„ Training_11660541.jpg\n",
            "        ğŸ“„ Training_11732399.jpg\n",
            "        ğŸ“„ Training_11753994.jpg\n",
            "        ğŸ“„ Training_11871637.jpg\n",
            "        ... (more files hidden)\n",
            "    ğŸ“ fear/\n",
            "        ğŸ“„ Training_10018621.jpg\n",
            "        ğŸ“„ Training_10031494.jpg\n",
            "        ğŸ“„ Training_10110501.jpg\n",
            "        ğŸ“„ Training_10117992.jpg\n",
            "        ğŸ“„ Training_10126156.jpg\n",
            "        ğŸ“„ Training_10127393.jpg\n",
            "        ğŸ“„ Training_10133194.jpg\n",
            "        ğŸ“„ Training_1018372.jpg\n",
            "        ğŸ“„ Training_10208260.jpg\n",
            "        ğŸ“„ Training_10230640.jpg\n",
            "        ... (more files hidden)\n",
            "    ğŸ“ happy/\n",
            "        ğŸ“„ Training_10019449.jpg\n",
            "        ğŸ“„ Training_10046809.jpg\n",
            "        ğŸ“„ Training_10066226.jpg\n",
            "        ğŸ“„ Training_10070997.jpg\n",
            "        ğŸ“„ Training_10080933.jpg\n",
            "        ğŸ“„ Training_10109375.jpg\n",
            "        ğŸ“„ Training_10116721.jpg\n",
            "        ğŸ“„ Training_10127474.jpg\n",
            "        ğŸ“„ Training_10133389.jpg\n",
            "        ğŸ“„ Training_10139297.jpg\n",
            "        ... (more files hidden)\n",
            "    ğŸ“ neutral/\n",
            "        ğŸ“„ Training_10002154.jpg\n",
            "        ğŸ“„ Training_10031781.jpg\n",
            "        ğŸ“„ Training_10055498.jpg\n",
            "        ğŸ“„ Training_10059941.jpg\n",
            "        ğŸ“„ Training_10078021.jpg\n",
            "        ğŸ“„ Training_10081559.jpg\n",
            "        ğŸ“„ Training_10082848.jpg\n",
            "        ğŸ“„ Training_10083265.jpg\n",
            "        ğŸ“„ Training_10088257.jpg\n",
            "        ğŸ“„ Training_10133788.jpg\n",
            "        ... (more files hidden)\n",
            "    ğŸ“ sad/\n",
            "        ğŸ“„ Training_10022789.jpg\n",
            "        ğŸ“„ Training_10031481.jpg\n",
            "        ğŸ“„ Training_10048646.jpg\n",
            "        ğŸ“„ Training_10057152.jpg\n",
            "        ğŸ“„ Training_10091569.jpg\n",
            "        ğŸ“„ Training_10094936.jpg\n",
            "        ğŸ“„ Training_10099928.jpg\n",
            "        ğŸ“„ Training_10111384.jpg\n",
            "        ğŸ“„ Training_10115766.jpg\n",
            "        ğŸ“„ Training_10118724.jpg\n",
            "        ... (more files hidden)\n",
            "    ğŸ“ surprise/\n",
            "        ğŸ“„ Training_10013223.jpg\n",
            "        ğŸ“„ Training_1002457.jpg\n",
            "        ğŸ“„ Training_10028230.jpg\n",
            "        ğŸ“„ Training_10060820.jpg\n",
            "        ğŸ“„ Training_10073433.jpg\n",
            "        ğŸ“„ Training_1009179.jpg\n",
            "        ğŸ“„ Training_10124215.jpg\n",
            "        ğŸ“„ Training_10135912.jpg\n",
            "        ğŸ“„ Training_10191209.jpg\n",
            "        ğŸ“„ Training_10218600.jpg\n",
            "        ... (more files hidden)\n",
            "ğŸ“ val/\n",
            "    âŒ è©²å­è³‡æ–™å¤¾ä¸å­˜åœ¨\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def show_rafdb_structure(root_dir, indent=\"\", max_files=10):\n",
        "    for folder in sorted(os.listdir(root_dir)):\n",
        "        folder_path = os.path.join(root_dir, folder)\n",
        "        if os.path.isdir(folder_path):\n",
        "            print(f\"{indent}ğŸ“ {folder}/\")\n",
        "            count = 0\n",
        "            for file in sorted(os.listdir(folder_path)):\n",
        "                if os.path.isfile(os.path.join(folder_path, file)):\n",
        "                    if count < max_files:\n",
        "                        print(f\"{indent}    ğŸ“„ {file}\")\n",
        "                        count += 1\n",
        "                    elif count == max_files:\n",
        "                        print(f\"{indent}    ... (more files hidden)\")\n",
        "                        break\n",
        "\n",
        "print(\"ğŸ—‚ï¸  raf-db è³‡æ–™å¤¾çµæ§‹:\\n\")\n",
        "raf_path = \"/content/raf-db\"\n",
        "if os.path.exists(raf_path):\n",
        "    for split in [\"train\", \"val\"]:\n",
        "        split_path = os.path.join(raf_path, split)\n",
        "        print(f\"ğŸ“ {split}/\")\n",
        "        if os.path.exists(split_path):\n",
        "            show_rafdb_structure(split_path, indent=\"    \")\n",
        "        else:\n",
        "            print(\"    âŒ è©²å­è³‡æ–™å¤¾ä¸å­˜åœ¨\")\n",
        "else:\n",
        "    print(\"âŒ raf-db è³‡æ–™å¤¾ä¸å­˜åœ¨\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnOIbmuZ2ofy",
        "outputId": "6b453e63-bc84-487a-ff95-e6e54348c219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ—‚ï¸  raf-db è³‡æ–™å¤¾çµæ§‹:\n",
            "\n",
            "ğŸ“ train/\n",
            "    âŒ è©²å­è³‡æ–™å¤¾ä¸å­˜åœ¨\n",
            "ğŸ“ val/\n",
            "    âŒ è©²å­è³‡æ–™å¤¾ä¸å­˜åœ¨\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## modify the structure of dataset to fit model"
      ],
      "metadata": {
        "id": "dXFDM19t56N5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "# label å°æ‡‰è¡¨\n",
        "label_map = {\n",
        "    1: \"surprise\",\n",
        "    2: \"fear\",\n",
        "    3: \"disgust\",\n",
        "    4: \"happy\",\n",
        "    5: \"sad\",\n",
        "    6: \"angry\",\n",
        "    7: \"neutral\"\n",
        "}\n",
        "\n",
        "def organize_rafdb_split(split_name):\n",
        "    csv_path = f\"/content/raf-db/{split_name}_labels.csv\"\n",
        "    src_root = f\"/content/raf-db/DATASET/{split_name}\"\n",
        "    dst_root = f\"/content/raf-db-imagefolder/{split_name}\"\n",
        "\n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(f\"ğŸ”„ æ­£åœ¨æ•´ç† {split_name} é›†ï¼Œå…± {len(df)} å¼µåœ–åƒ\")\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        filename = row[\"image\"]\n",
        "        label = label_map[row[\"label\"]]\n",
        "\n",
        "        # æœå°‹åœ–åƒä½æ–¼ 1~7 å­è³‡æ–™å¤¾ä¸­\n",
        "        found = False\n",
        "        for i in range(1, 8):\n",
        "            potential_path = os.path.join(src_root, str(i), filename)\n",
        "            if os.path.exists(potential_path):\n",
        "                save_dir = os.path.join(dst_root, label)\n",
        "                os.makedirs(save_dir, exist_ok=True)\n",
        "                shutil.copy(potential_path, os.path.join(save_dir, filename))\n",
        "                found = True\n",
        "                break\n",
        "\n",
        "        if not found:\n",
        "            print(f\"âš ï¸ æ‰¾ä¸åˆ°åœ–æª”ï¼š{filename}\")\n",
        "\n",
        "# åŸ·è¡Œ\n",
        "organize_rafdb_split(\"train\")\n",
        "organize_rafdb_split(\"test\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQLA5RSt4HBR",
        "outputId": "38561aec-e311-4bc6-9881-d1ba6733e747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”„ æ­£åœ¨æ•´ç† train é›†ï¼Œå…± 12271 å¼µåœ–åƒ\n",
            "ğŸ”„ æ­£åœ¨æ•´ç† test é›†ï¼Œå…± 3068 å¼µåœ–åƒ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# trainning"
      ],
      "metadata": {
        "id": "qeaQgYiG6BfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸš¨ ä¸€æ¬¡è¨“ç·´ 2 è³‡æ–™é›† Ã— 4 æ¨¡å‹ = 8 çµ„ï¼Œå¼·åˆ¶ä½¿ç”¨ GPU\n",
        "\n",
        "import os, time\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# âœ… å¼·åˆ¶æª¢æŸ¥ GPU\n",
        "if not torch.cuda.is_available():\n",
        "    raise RuntimeError(\"âŒ CUDA/GPU is not available! Please switch Colab runtime to GPU.\")\n",
        "else:\n",
        "    print(\"âœ… CUDA detected:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "# âœ… æ¨¡å‹å»ºç«‹å™¨\n",
        "def get_model(name, num_classes):\n",
        "    if name == \"resnet18\":\n",
        "        model = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    elif name == \"vgg16\":\n",
        "        model = torchvision.models.vgg16(weights=torchvision.models.VGG16_Weights.DEFAULT)\n",
        "        model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
        "    elif name == \"efficientnet_b0\":\n",
        "        model = torchvision.models.efficientnet_b0(weights=torchvision.models.EfficientNet_B0_Weights.DEFAULT)\n",
        "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "    elif name == \"mobilenet_v2\":\n",
        "        model = torchvision.models.mobilenet_v2(weights=torchvision.models.MobileNet_V2_Weights.DEFAULT)\n",
        "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model: {name}\")\n",
        "    return model\n",
        "\n",
        "# âœ… è¨“ç·´å‡½æ•¸\n",
        "def train_model(model_name, dataset_name, data_path, val_folder=\"test\", num_epochs=5, batch_size=64):\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"\\nğŸ§  Training [{model_name}] on [{dataset_name}] using [{device}]\")\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    train_data = ImageFolder(os.path.join(data_path, \"train\"), transform=transform)\n",
        "    val_data = ImageFolder(os.path.join(data_path, val_folder), transform=transform)\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = get_model(model_name, num_classes=len(train_data.classes)).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    train_loss_list, val_acc_list = [], []\n",
        "    start = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        train_loss_list.append(avg_loss)\n",
        "\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (preds == labels).sum().item()\n",
        "        val_acc = correct / total\n",
        "        val_acc_list.append(val_acc)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] | Loss: {avg_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    duration = round(time.time() - start, 2)\n",
        "    print(f\"âœ… Done {model_name} on {dataset_name} in {duration}s\")\n",
        "\n",
        "    save_dir = f\"/content/saved_models/{dataset_name}\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    save_path = os.path.join(save_dir, f\"{model_name}.pth\")\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f\"ğŸ’¾ Saved to: {save_path}\")\n",
        "\n",
        "    del model\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return {\n",
        "        \"model\": model_name,\n",
        "        \"dataset\": dataset_name,\n",
        "        \"epochs\": num_epochs,\n",
        "        \"final_loss\": round(train_loss_list[-1], 4),\n",
        "        \"final_val_acc\": round(val_acc_list[-1], 4),\n",
        "        \"duration_sec\": duration\n",
        "    }\n",
        "\n",
        "# âœ… è¨“ç·´æ‰€æœ‰æ¨¡å‹çµ„åˆ\n",
        "models = [\"resnet18\", \"vgg16\", \"efficientnet_b0\", \"mobilenet_v2\"]\n",
        "datasets = {\n",
        "    \"fer2013\": { \"path\": \"/content/fer2013\", \"val_folder\": \"test\" },\n",
        "    \"raf-db\": { \"path\": \"/content/raf-db-imagefolder\", \"val_folder\": \"test\" }\n",
        "}\n",
        "\n",
        "results = []\n",
        "for dataset_name, config in datasets.items():\n",
        "    for model_name in models:\n",
        "        result = train_model(\n",
        "            model_name=model_name,\n",
        "            dataset_name=dataset_name,\n",
        "            data_path=config[\"path\"],\n",
        "            val_folder=config[\"val_folder\"],\n",
        "            num_epochs=5\n",
        "        )\n",
        "        results.append(result)\n",
        "\n",
        "# âœ… å„²å­˜è¨“ç·´çµæœ\n",
        "df = pd.DataFrame(results)\n",
        "os.makedirs(\"/content/saved_models\", exist_ok=True)\n",
        "df.to_csv(\"/content/saved_models/training_summary.csv\", index=False)\n",
        "print(\"ğŸ“Š Summary saved to /content/saved_models/training_summary.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5_Sxwqy5ZKr",
        "outputId": "8ab647d3-e1ed-48af-e802-4d2cd1497206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… CUDA detected: Tesla T4\n",
            "\n",
            "ğŸ§  Training [resnet18] on [fer2013] using [cuda]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [00:00<00:00, 217MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5] | Loss: 1.1326 | Val Acc: 0.6329\n",
            "Epoch [2/5] | Loss: 0.7716 | Val Acc: 0.6485\n",
            "Epoch [3/5] | Loss: 0.4768 | Val Acc: 0.6578\n",
            "Epoch [4/5] | Loss: 0.2133 | Val Acc: 0.6478\n",
            "Epoch [5/5] | Loss: 0.1004 | Val Acc: 0.6553\n",
            "âœ… Done resnet18 on fer2013 in 739.37s\n",
            "ğŸ’¾ Saved to: /content/saved_models/fer2013/resnet18.pth\n",
            "\n",
            "ğŸ§  Training [vgg16] on [fer2013] using [cuda]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 528M/528M [00:06<00:00, 85.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5] | Loss: 1.2595 | Val Acc: 0.5834\n",
            "Epoch [2/5] | Loss: 0.9585 | Val Acc: 0.6280\n",
            "Epoch [3/5] | Loss: 0.7777 | Val Acc: 0.6599\n",
            "Epoch [4/5] | Loss: 0.5839 | Val Acc: 0.6645\n",
            "Epoch [5/5] | Loss: 0.4027 | Val Acc: 0.6670\n",
            "âœ… Done vgg16 on fer2013 in 2463.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ’¾ Saved to: /content/saved_models/fer2013/vgg16.pth\n",
            "\n",
            "ğŸ§  Training [efficientnet_b0] on [fer2013] using [cuda]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20.5M/20.5M [00:00<00:00, 215MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5] | Loss: 1.2974 | Val Acc: 0.6038\n",
            "Epoch [2/5] | Loss: 0.9458 | Val Acc: 0.6427\n",
            "Epoch [3/5] | Loss: 0.7765 | Val Acc: 0.6612\n",
            "Epoch [4/5] | Loss: 0.6274 | Val Acc: 0.6658\n",
            "Epoch [5/5] | Loss: 0.4854 | Val Acc: 0.6624\n",
            "âœ… Done efficientnet_b0 on fer2013 in 988.46s\n",
            "ğŸ’¾ Saved to: /content/saved_models/fer2013/efficientnet_b0.pth\n",
            "\n",
            "ğŸ§  Training [mobilenet_v2] on [fer2013] using [cuda]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-7ebf99e0.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-7ebf99e0.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13.6M/13.6M [00:00<00:00, 140MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5] | Loss: 1.3628 | Val Acc: 0.5673\n",
            "Epoch [2/5] | Loss: 1.0074 | Val Acc: 0.6089\n",
            "Epoch [3/5] | Loss: 0.8062 | Val Acc: 0.6273\n",
            "Epoch [4/5] | Loss: 0.6023 | Val Acc: 0.6176\n",
            "Epoch [5/5] | Loss: 0.3957 | Val Acc: 0.6271\n",
            "âœ… Done mobilenet_v2 on fer2013 in 829.01s\n",
            "ğŸ’¾ Saved to: /content/saved_models/fer2013/mobilenet_v2.pth\n",
            "\n",
            "ğŸ§  Training [resnet18] on [raf-db] using [cuda]\n",
            "Epoch [1/5] | Loss: 0.8959 | Val Acc: 0.7526\n",
            "Epoch [2/5] | Loss: 0.4109 | Val Acc: 0.7738\n",
            "Epoch [3/5] | Loss: 0.1449 | Val Acc: 0.7868\n",
            "Epoch [4/5] | Loss: 0.0418 | Val Acc: 0.8061\n",
            "Epoch [5/5] | Loss: 0.0150 | Val Acc: 0.8220\n",
            "âœ… Done resnet18 on raf-db in 320.92s\n",
            "ğŸ’¾ Saved to: /content/saved_models/raf-db/resnet18.pth\n",
            "\n",
            "ğŸ§  Training [vgg16] on [raf-db] using [cuda]\n",
            "Epoch [1/5] | Loss: 1.0437 | Val Acc: 0.7405\n",
            "Epoch [2/5] | Loss: 0.6506 | Val Acc: 0.8035\n",
            "Epoch [3/5] | Loss: 0.4282 | Val Acc: 0.7969\n",
            "Epoch [4/5] | Loss: 0.2713 | Val Acc: 0.7872\n",
            "Epoch [5/5] | Loss: 0.1711 | Val Acc: 0.8184\n",
            "âœ… Done vgg16 on raf-db in 1067.01s\n",
            "ğŸ’¾ Saved to: /content/saved_models/raf-db/vgg16.pth\n",
            "\n",
            "ğŸ§  Training [efficientnet_b0] on [raf-db] using [cuda]\n",
            "Epoch [1/5] | Loss: 1.2678 | Val Acc: 0.7027\n",
            "Epoch [2/5] | Loss: 0.7592 | Val Acc: 0.7673\n",
            "Epoch [3/5] | Loss: 0.5278 | Val Acc: 0.7872\n",
            "Epoch [4/5] | Loss: 0.3640 | Val Acc: 0.7885\n",
            "Epoch [5/5] | Loss: 0.2452 | Val Acc: 0.8044\n",
            "âœ… Done efficientnet_b0 on raf-db in 434.43s\n",
            "ğŸ’¾ Saved to: /content/saved_models/raf-db/efficientnet_b0.pth\n",
            "\n",
            "ğŸ§  Training [mobilenet_v2] on [raf-db] using [cuda]\n",
            "Epoch [1/5] | Loss: 1.3894 | Val Acc: 0.6235\n",
            "Epoch [2/5] | Loss: 0.8945 | Val Acc: 0.7099\n",
            "Epoch [3/5] | Loss: 0.6207 | Val Acc: 0.7399\n",
            "Epoch [4/5] | Loss: 0.3928 | Val Acc: 0.7458\n",
            "Epoch [5/5] | Loss: 0.2297 | Val Acc: 0.7428\n",
            "âœ… Done mobilenet_v2 on raf-db in 364.9s\n",
            "ğŸ’¾ Saved to: /content/saved_models/raf-db/mobilenet_v2.pth\n",
            "ğŸ“Š Summary saved to /content/saved_models/training_summary.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IZ7LrIiUekA6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}